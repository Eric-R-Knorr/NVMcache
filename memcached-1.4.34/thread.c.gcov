        -:    0:Source:thread.c
        -:    0:Graph:thread.gcno
        -:    0:Data:thread.gcda
        -:    0:Runs:183
        -:    1:/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */
        -:    2:/*
        -:    3: * Thread management for memcached.
        -:    4: */
        -:    5:#include "memcached.h"
        -:    6:#include <assert.h>
        -:    7:#include <stdio.h>
        -:    8:#include <errno.h>
        -:    9:#include <stdlib.h>
        -:   10:#include <string.h>
        -:   11:#include <pthread.h>
        -:   12:
        -:   13:#ifdef __sun
        -:   14:#include <atomic.h>
        -:   15:#endif
        -:   16:
        -:   17:#define ITEMS_PER_ALLOC 64
        -:   18:
        -:   19:/* An item in the connection queue. */
        -:   20:typedef struct conn_queue_item CQ_ITEM;
        -:   21:struct conn_queue_item {
        -:   22:    int               sfd;
        -:   23:    enum conn_states  init_state;
        -:   24:    int               event_flags;
        -:   25:    int               read_buffer_size;
        -:   26:    enum network_transport     transport;
        -:   27:    conn *c;
        -:   28:    CQ_ITEM          *next;
        -:   29:};
        -:   30:
        -:   31:/* A connection queue. */
        -:   32:typedef struct conn_queue CQ;
        -:   33:struct conn_queue {
        -:   34:    CQ_ITEM *head;
        -:   35:    CQ_ITEM *tail;
        -:   36:    pthread_mutex_t lock;
        -:   37:};
        -:   38:
        -:   39:/* Locks for cache LRU operations */
        -:   40:pthread_mutex_t lru_locks[POWER_LARGEST];
        -:   41:
        -:   42:/* Connection lock around accepting new connections */
        -:   43:pthread_mutex_t conn_lock = PTHREAD_MUTEX_INITIALIZER;
        -:   44:
        -:   45:#if !defined(HAVE_GCC_ATOMICS) && !defined(__sun)
        -:   46:pthread_mutex_t atomics_mutex = PTHREAD_MUTEX_INITIALIZER;
        -:   47:#endif
        -:   48:
        -:   49:/* Lock for global stats */
        -:   50:static pthread_mutex_t stats_lock = PTHREAD_MUTEX_INITIALIZER;
        -:   51:
        -:   52:/* Lock to cause worker threads to hang up after being woken */
        -:   53:static pthread_mutex_t worker_hang_lock;
        -:   54:
        -:   55:/* Free list of CQ_ITEM structs */
        -:   56:static CQ_ITEM *cqi_freelist;
        -:   57:static pthread_mutex_t cqi_freelist_lock;
        -:   58:
        -:   59:static pthread_mutex_t *item_locks;
        -:   60:/* size of the item lock hash table */
        -:   61:static uint32_t item_lock_count;
        -:   62:unsigned int item_lock_hashpower;
        -:   63:#define hashsize(n) ((unsigned long int)1<<(n))
        -:   64:#define hashmask(n) (hashsize(n)-1)
        -:   65:
        -:   66:/*
        -:   67: * Each libevent instance has a wakeup pipe, which other threads
        -:   68: * can use to signal that they've put a new connection on its queue.
        -:   69: */
        -:   70:static LIBEVENT_THREAD *threads;
        -:   71:
        -:   72:/*
        -:   73: * Number of worker threads that have finished setting themselves up.
        -:   74: */
        -:   75:static int init_count = 0;
        -:   76:static pthread_mutex_t init_lock;
        -:   77:static pthread_cond_t init_cond;
        -:   78:
        -:   79:
        -:   80:static void thread_libevent_process(int fd, short which, void *arg);
        -:   81:
   339893:   82:unsigned short refcount_incr(unsigned short *refcount) {
        -:   83:#ifdef HAVE_GCC_ATOMICS
   339893:   84:    return __sync_add_and_fetch(refcount, 1);
        -:   85:#elif defined(__sun)
        -:   86:    return atomic_inc_ushort_nv(refcount);
        -:   87:#else
        -:   88:    unsigned short res;
        -:   89:    mutex_lock(&atomics_mutex);
        -:   90:    (*refcount)++;
        -:   91:    res = *refcount;
        -:   92:    mutex_unlock(&atomics_mutex);
        -:   93:    return res;
        -:   94:#endif
        -:   95:}
        -:   96:
   417216:   97:unsigned short refcount_decr(unsigned short *refcount) {
        -:   98:#ifdef HAVE_GCC_ATOMICS
   417216:   99:    return __sync_sub_and_fetch(refcount, 1);
        -:  100:#elif defined(__sun)
        -:  101:    return atomic_dec_ushort_nv(refcount);
        -:  102:#else
        -:  103:    unsigned short res;
        -:  104:    mutex_lock(&atomics_mutex);
        -:  105:    (*refcount)--;
        -:  106:    res = *refcount;
        -:  107:    mutex_unlock(&atomics_mutex);
        -:  108:    return res;
        -:  109:#endif
        -:  110:}
        -:  111:
        -:  112:/* item_lock() must be held for an item before any modifications to either its
        -:  113: * associated hash bucket, or the structure itself.
        -:  114: * LRU modifications must hold the item lock, and the LRU lock.
        -:  115: * LRU's accessing items must item_trylock() before modifying an item.
        -:  116: * Items accessible from an LRU must not be freed or modified
        -:  117: * without first locking and removing from the LRU.
        -:  118: */
        -:  119:
  391826*:  120:void item_lock(uint32_t hv) {
    #####:  121:    mutex_lock(&item_locks[hv & hashmask(item_lock_hashpower)]);
    #####:  122:}
        -:  123:
   166493:  124:void *item_trylock(uint32_t hv) {
   166493:  125:    pthread_mutex_t *lock = &item_locks[hv & hashmask(item_lock_hashpower)];
   166493:  126:    if (pthread_mutex_trylock(lock) == 0) {
   164714:  127:        return lock;
        -:  128:    }
        -:  129:    return NULL;
        -:  130:}
        -:  131:
   164714:  132:void item_trylock_unlock(void *lock) {
   164714:  133:    mutex_unlock((pthread_mutex_t *) lock);
   164714:  134:}
        -:  135:
  391826*:  136:void item_unlock(uint32_t hv) {
    #####:  137:    mutex_unlock(&item_locks[hv & hashmask(item_lock_hashpower)]);
    #####:  138:}
        -:  139:
       89:  140:static void wait_for_thread_registration(int nthreads) {
     264*:  141:    while (init_count < nthreads) {
     175*:  142:        pthread_cond_wait(&init_cond, &init_lock);
        -:  143:    }
        -:  144:}
        -:  145:
      356:  146:static void register_thread_initialized(void) {
      356:  147:    pthread_mutex_lock(&init_lock);
      356:  148:    init_count++;
      356:  149:    pthread_cond_signal(&init_cond);
      356:  150:    pthread_mutex_unlock(&init_lock);
        -:  151:    /* Force worker threads to pile up if someone wants us to */
      356:  152:    pthread_mutex_lock(&worker_hang_lock);
      356:  153:    pthread_mutex_unlock(&worker_hang_lock);
      356:  154:}
        -:  155:
        -:  156:/* Must not be called with any deeper locks held */
    #####:  157:void pause_threads(enum pause_thread_types type) {
    #####:  158:    char buf[1];
    #####:  159:    int i;
        -:  160:
    #####:  161:    buf[0] = 0;
    #####:  162:    switch (type) {
    #####:  163:        case PAUSE_ALL_THREADS:
    #####:  164:            slabs_rebalancer_pause();
    #####:  165:            lru_crawler_pause();
    #####:  166:            lru_maintainer_pause();
    #####:  167:        case PAUSE_WORKER_THREADS:
    #####:  168:            buf[0] = 'p';
    #####:  169:            pthread_mutex_lock(&worker_hang_lock);
    #####:  170:            break;
    #####:  171:        case RESUME_ALL_THREADS:
    #####:  172:            slabs_rebalancer_resume();
    #####:  173:            lru_crawler_resume();
    #####:  174:            lru_maintainer_resume();
    #####:  175:        case RESUME_WORKER_THREADS:
    #####:  176:            pthread_mutex_unlock(&worker_hang_lock);
    #####:  177:            break;
    #####:  178:        default:
    #####:  179:            fprintf(stderr, "Unknown lock type: %d\n", type);
    #####:  180:            assert(1 == 0);
        -:  181:            break;
        -:  182:    }
        -:  183:
        -:  184:    /* Only send a message if we have one. */
    #####:  185:    if (buf[0] == 0) {
    #####:  186:        return;
        -:  187:    }
        -:  188:
    #####:  189:    pthread_mutex_lock(&init_lock);
    #####:  190:    init_count = 0;
    #####:  191:    for (i = 0; i < settings.num_threads; i++) {
    #####:  192:        if (write(threads[i].notify_send_fd, buf, 1) != 1) {
    #####:  193:            perror("Failed writing to notify pipe");
        -:  194:            /* TODO: This is a fatal problem. Can it ever happen temporarily? */
        -:  195:        }
        -:  196:    }
    #####:  197:    wait_for_thread_registration(settings.num_threads);
    #####:  198:    pthread_mutex_unlock(&init_lock);
        -:  199:}
        -:  200:
        -:  201:/*
        -:  202: * Initializes a connection queue.
        -:  203: */
      356:  204:static void cq_init(CQ *cq) {
      356:  205:    pthread_mutex_init(&cq->lock, NULL);
      356:  206:    cq->head = NULL;
      356:  207:    cq->tail = NULL;
        -:  208:}
        -:  209:
        -:  210:/*
        -:  211: * Looks for an item on a connection queue, but doesn't block if there isn't
        -:  212: * one.
        -:  213: * Returns the item, or NULL if no item is available
        -:  214: */
      745:  215:static CQ_ITEM *cq_pop(CQ *cq) {
      745:  216:    CQ_ITEM *item;
        -:  217:
      745:  218:    pthread_mutex_lock(&cq->lock);
      745:  219:    item = cq->head;
      745:  220:    if (NULL != item) {
      745:  221:        cq->head = item->next;
      745:  222:        if (NULL == cq->head)
      737:  223:            cq->tail = NULL;
        -:  224:    }
      745:  225:    pthread_mutex_unlock(&cq->lock);
        -:  226:
      745:  227:    return item;
        -:  228:}
        -:  229:
        -:  230:/*
        -:  231: * Adds an item to a connection queue.
        -:  232: */
      745:  233:static void cq_push(CQ *cq, CQ_ITEM *item) {
      745:  234:    item->next = NULL;
        -:  235:
      745:  236:    pthread_mutex_lock(&cq->lock);
      745:  237:    if (NULL == cq->tail)
      737:  238:        cq->head = item;
        -:  239:    else
        8:  240:        cq->tail->next = item;
      745:  241:    cq->tail = item;
      745:  242:    pthread_mutex_unlock(&cq->lock);
      745:  243:}
        -:  244:
        -:  245:/*
        -:  246: * Returns a fresh connection queue item.
        -:  247: */
      745:  248:static CQ_ITEM *cqi_new(void) {
      745:  249:    CQ_ITEM *item = NULL;
      745:  250:    pthread_mutex_lock(&cqi_freelist_lock);
      745:  251:    if (cqi_freelist) {
      661:  252:        item = cqi_freelist;
      661:  253:        cqi_freelist = item->next;
        -:  254:    }
      745:  255:    pthread_mutex_unlock(&cqi_freelist_lock);
        -:  256:
      745:  257:    if (NULL == item) {
       84:  258:        int i;
        -:  259:
        -:  260:        /* Allocate a bunch of items at once to reduce fragmentation */
       84:  261:        item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC);
       84:  262:        if (NULL == item) {
    #####:  263:            STATS_LOCK();
    #####:  264:            stats.malloc_fails++;
    #####:  265:            STATS_UNLOCK();
    #####:  266:            return NULL;
        -:  267:        }
        -:  268:
        -:  269:        /*
        -:  270:         * Link together all the new items except the first one
        -:  271:         * (which we'll return to the caller) for placement on
        -:  272:         * the freelist.
        -:  273:         */
     5292:  274:        for (i = 2; i < ITEMS_PER_ALLOC; i++)
     5208:  275:            item[i - 1].next = &item[i];
        -:  276:
       84:  277:        pthread_mutex_lock(&cqi_freelist_lock);
       84:  278:        item[ITEMS_PER_ALLOC - 1].next = cqi_freelist;
       84:  279:        cqi_freelist = &item[1];
       84:  280:        pthread_mutex_unlock(&cqi_freelist_lock);
        -:  281:    }
        -:  282:
        -:  283:    return item;
        -:  284:}
        -:  285:
        -:  286:
        -:  287:/*
        -:  288: * Frees a connection queue item (adds it to the freelist.)
        -:  289: */
      745:  290:static void cqi_free(CQ_ITEM *item) {
      745:  291:    pthread_mutex_lock(&cqi_freelist_lock);
      745:  292:    item->next = cqi_freelist;
      745:  293:    cqi_freelist = item;
      745:  294:    pthread_mutex_unlock(&cqi_freelist_lock);
      745:  295:}
        -:  296:
        -:  297:
        -:  298:/*
        -:  299: * Creates a worker thread.
        -:  300: */
      356:  301:static void create_worker(void *(*func)(void *), void *arg) {
      356:  302:    pthread_attr_t  attr;
      356:  303:    int             ret;
        -:  304:
      356:  305:    pthread_attr_init(&attr);
        -:  306:
      356:  307:    if ((ret = pthread_create(&((LIBEVENT_THREAD*)arg)->thread_id, &attr, func, arg)) != 0) {
    #####:  308:        fprintf(stderr, "Can't create thread: %s\n",
        -:  309:                strerror(ret));
    #####:  310:        exit(1);
        -:  311:    }
      356:  312:}
        -:  313:
        -:  314:/*
        -:  315: * Sets whether or not we accept new connections.
        -:  316: */
    #####:  317:void accept_new_conns(const bool do_accept) {
    #####:  318:    pthread_mutex_lock(&conn_lock);
    #####:  319:    do_accept_new_conns(do_accept);
    #####:  320:    pthread_mutex_unlock(&conn_lock);
    #####:  321:}
        -:  322:/****************************** LIBEVENT THREADS *****************************/
        -:  323:
        -:  324:/*
        -:  325: * Set up a thread's information.
        -:  326: */
      356:  327:static void setup_thread(LIBEVENT_THREAD *me) {
      356:  328:    me->base = event_init();
      356:  329:    if (! me->base) {
    #####:  330:        fprintf(stderr, "Can't allocate event base\n");
    #####:  331:        exit(1);
        -:  332:    }
        -:  333:
        -:  334:    /* Listen for notifications from other threads */
      356:  335:    event_set(&me->notify_event, me->notify_receive_fd,
        -:  336:              EV_READ | EV_PERSIST, thread_libevent_process, me);
      356:  337:    event_base_set(me->base, &me->notify_event);
        -:  338:
      356:  339:    if (event_add(&me->notify_event, 0) == -1) {
    #####:  340:        fprintf(stderr, "Can't monitor libevent notify pipe\n");
    #####:  341:        exit(1);
        -:  342:    }
        -:  343:
      356:  344:    me->new_conn_queue = malloc(sizeof(struct conn_queue));
      356:  345:    if (me->new_conn_queue == NULL) {
    #####:  346:        perror("Failed to allocate memory for connection queue");
    #####:  347:        exit(EXIT_FAILURE);
        -:  348:    }
      356:  349:    cq_init(me->new_conn_queue);
        -:  350:
      356:  351:    if (pthread_mutex_init(&me->stats.mutex, NULL) != 0) {
    #####:  352:        perror("Failed to initialize mutex");
    #####:  353:        exit(EXIT_FAILURE);
        -:  354:    }
        -:  355:
      356:  356:    me->suffix_cache = cache_create("suffix", SUFFIX_SIZE, sizeof(char*),
        -:  357:                                    NULL, NULL);
      356:  358:    if (me->suffix_cache == NULL) {
    #####:  359:        fprintf(stderr, "Failed to create suffix cache\n");
    #####:  360:        exit(EXIT_FAILURE);
        -:  361:    }
      356:  362:}
        -:  363:
        -:  364:/*
        -:  365: * Worker thread: main event loop
        -:  366: */
      356:  367:static void *worker_libevent(void *arg) {
      356:  368:    LIBEVENT_THREAD *me = arg;
        -:  369:
        -:  370:    /* Any per-thread setup can happen here; memcached_thread_init() will block until
        -:  371:     * all threads have finished initializing.
        -:  372:     */
      356:  373:    me->l = logger_create();
      356:  374:    if (me->l == NULL) {
    #####:  375:        abort();
        -:  376:    }
        -:  377:
      356:  378:    register_thread_initialized();
        -:  379:
      356:  380:    event_base_loop(me->base, 0);
    #####:  381:    return NULL;
        -:  382:}
        -:  383:
        -:  384:
        -:  385:/*
        -:  386: * Processes an incoming "handle a new connection" item. This is called when
        -:  387: * input arrives on the libevent wakeup pipe.
        -:  388: */
      746:  389:static void thread_libevent_process(int fd, short which, void *arg) {
      746:  390:    LIBEVENT_THREAD *me = arg;
      746:  391:    CQ_ITEM *item;
      746:  392:    char buf[1];
      746:  393:    unsigned int timeout_fd;
        -:  394:
      746:  395:    if (read(fd, buf, 1) != 1) {
    #####:  396:        if (settings.verbose > 0)
    #####:  397:            fprintf(stderr, "Can't read from libevent pipe\n");
    #####:  398:        return;
        -:  399:    }
        -:  400:
      746:  401:    switch (buf[0]) {
      745:  402:    case 'c':
      745:  403:        item = cq_pop(me->new_conn_queue);
        -:  404:
      745:  405:        if (NULL != item) {
      745:  406:            conn *c = conn_new(item->sfd, item->init_state, item->event_flags,
        -:  407:                               item->read_buffer_size, item->transport,
        -:  408:                               me->base);
      745:  409:            if (c == NULL) {
    #####:  410:                if (IS_UDP(item->transport)) {
    #####:  411:                    fprintf(stderr, "Can't listen for events on UDP socket\n");
    #####:  412:                    exit(1);
        -:  413:                } else {
    #####:  414:                    if (settings.verbose > 0) {
    #####:  415:                        fprintf(stderr, "Can't listen for events on fd %d\n",
        -:  416:                            item->sfd);
        -:  417:                    }
    #####:  418:                    close(item->sfd);
        -:  419:                }
        -:  420:            } else {
      745:  421:                c->thread = me;
        -:  422:            }
      745:  423:            cqi_free(item);
        -:  424:        }
        -:  425:        break;
    #####:  426:    case 'r':
    #####:  427:        item = cq_pop(me->new_conn_queue);
        -:  428:
    #####:  429:        if (NULL != item) {
    #####:  430:            conn_worker_readd(item->c);
    #####:  431:            cqi_free(item);
        -:  432:        }
        -:  433:        break;
        -:  434:    /* we were told to pause and report in */
    #####:  435:    case 'p':
    #####:  436:        register_thread_initialized();
    #####:  437:        break;
        -:  438:    /* a client socket timed out */
        -:  439:    case 't':
        1:  440:        if (read(fd, &timeout_fd, sizeof(timeout_fd)) != sizeof(timeout_fd)) {
    #####:  441:            if (settings.verbose > 0)
    #####:  442:                fprintf(stderr, "Can't read timeout fd from libevent pipe\n");
    #####:  443:            return;
        -:  444:        }
        1:  445:        conn_close_idle(conns[timeout_fd]);
        1:  446:        break;
        -:  447:    }
      746:  448:}
        -:  449:
        -:  450:/* Which thread we assigned a connection to most recently. */
        -:  451:static int last_thread = -1;
        -:  452:
        -:  453:/*
        -:  454: * Dispatches a new connection to another thread. This is only ever called
        -:  455: * from the main thread, either during initialization (for UDP) or because
        -:  456: * of an incoming connection.
        -:  457: */
      745:  458:void dispatch_conn_new(int sfd, enum conn_states init_state, int event_flags,
        -:  459:                       int read_buffer_size, enum network_transport transport) {
      745:  460:    CQ_ITEM *item = cqi_new();
      745:  461:    char buf[1];
      745:  462:    if (item == NULL) {
    #####:  463:        close(sfd);
        -:  464:        /* given that malloc failed this may also fail, but let's try */
    #####:  465:        fprintf(stderr, "Failed to allocate memory for connection object\n");
    #####:  466:        return ;
        -:  467:    }
        -:  468:
      745:  469:    int tid = (last_thread + 1) % settings.num_threads;
        -:  470:
      745:  471:    LIBEVENT_THREAD *thread = threads + tid;
        -:  472:
      745:  473:    last_thread = tid;
        -:  474:
      745:  475:    item->sfd = sfd;
      745:  476:    item->init_state = init_state;
      745:  477:    item->event_flags = event_flags;
      745:  478:    item->read_buffer_size = read_buffer_size;
      745:  479:    item->transport = transport;
        -:  480:
      745:  481:    cq_push(thread->new_conn_queue, item);
        -:  482:
      745:  483:    MEMCACHED_CONN_DISPATCH(sfd, thread->thread_id);
      745:  484:    buf[0] = 'c';
      745:  485:    if (write(thread->notify_send_fd, buf, 1) != 1) {
    #####:  486:        perror("Writing to thread notify pipe");
        -:  487:    }
        -:  488:}
        -:  489:
        -:  490:/*
        -:  491: * Re-dispatches a connection back to the original thread. Can be called from
        -:  492: * any side thread borrowing a connection.
        -:  493: */
    #####:  494:void redispatch_conn(conn *c) {
    #####:  495:    CQ_ITEM *item = cqi_new();
    #####:  496:    char buf[1];
    #####:  497:    if (item == NULL) {
        -:  498:        /* Can't cleanly redispatch connection. close it forcefully. */
    #####:  499:        c->state = conn_closed;
    #####:  500:        close(c->sfd);
    #####:  501:        return;
        -:  502:    }
    #####:  503:    LIBEVENT_THREAD *thread = c->thread;
    #####:  504:    item->sfd = c->sfd;
    #####:  505:    item->init_state = conn_new_cmd;
    #####:  506:    item->c = c;
        -:  507:
    #####:  508:    cq_push(thread->new_conn_queue, item);
        -:  509:
    #####:  510:    buf[0] = 'r';
    #####:  511:    if (write(thread->notify_send_fd, buf, 1) != 1) {
    #####:  512:        perror("Writing to thread notify pipe");
        -:  513:    }
        -:  514:}
        -:  515:
        -:  516:/* This misses the allow_new_conns flag :( */
        3:  517:void sidethread_conn_close(conn *c) {
        3:  518:    c->state = conn_closed;
        3:  519:    if (settings.verbose > 1)
    #####:  520:        fprintf(stderr, "<%d connection closed from side thread.\n", c->sfd);
        3:  521:    close(c->sfd);
        -:  522:
        3:  523:    STATS_LOCK();
        3:  524:    stats_state.curr_conns--;
        3:  525:    STATS_UNLOCK();
        -:  526:
        3:  527:    return;
        -:  528:}
        -:  529:
        -:  530:/********************************* ITEM ACCESS *******************************/
        -:  531:
        -:  532:/*
        -:  533: * Allocates a new item.
        -:  534: */
   154639:  535:item *item_alloc(char *key, size_t nkey, int flags, rel_time_t exptime, int nbytes) {
   154639:  536:    item *it;
        -:  537:    /* do_item_alloc handles its own locks */
   154639:  538:    it = do_item_alloc(key, nkey, flags, exptime, nbytes);
   154639:  539:    return it;
        -:  540:}
        -:  541:
        -:  542:/*
        -:  543: * Returns an item if it hasn't been marked as expired,
        -:  544: * lazy-expiring as needed.
        -:  545: */
   116624:  546:item *item_get(const char *key, const size_t nkey, conn *c) {
   116624:  547:    item *it;
   116624:  548:    uint32_t hv;
   116624:  549:    hv = hash(key, nkey);
   116624:  550:    item_lock(hv);
   116624:  551:    it = do_item_get(key, nkey, hv, c);
   116624:  552:    item_unlock(hv);
   116624:  553:    return it;
        -:  554:}
        -:  555:
      101:  556:item *item_touch(const char *key, size_t nkey, uint32_t exptime, conn *c) {
      101:  557:    item *it;
      101:  558:    uint32_t hv;
      101:  559:    hv = hash(key, nkey);
      101:  560:    item_lock(hv);
      101:  561:    it = do_item_touch(key, nkey, exptime, hv, c);
      101:  562:    item_unlock(hv);
      101:  563:    return it;
        -:  564:}
        -:  565:
        -:  566:/*
        -:  567: * Links an item into the LRU and hashtable.
        -:  568: */
    #####:  569:int item_link(item *item) {
    #####:  570:    int ret;
    #####:  571:    uint32_t hv;
        -:  572:
    #####:  573:    hv = hash(ITEM_key(item), item->nkey);
    #####:  574:    item_lock(hv);
    #####:  575:    ret = do_item_link(item, hv);
    #####:  576:    item_unlock(hv);
    #####:  577:    return ret;
        -:  578:}
        -:  579:
        -:  580:/*
        -:  581: * Decrements the reference count on an item and adds it to the freelist if
        -:  582: * needed.
        -:  583: */
   137352:  584:void item_remove(item *item) {
   137352:  585:    uint32_t hv;
   137352:  586:    hv = hash(ITEM_key(item), item->nkey);
        -:  587:
   137352:  588:    item_lock(hv);
   137352:  589:    do_item_remove(item);
   137352:  590:    item_unlock(hv);
   137352:  591:}
        -:  592:
        -:  593:/*
        -:  594: * Replaces one item with another in the hashtable.
        -:  595: * Unprotected by a mutex lock since the core server does not require
        -:  596: * it to be thread-safe.
        -:  597: */
    35986:  598:int item_replace(item *old_it, item *new_it, const uint32_t hv) {
    35986:  599:    return do_item_replace(old_it, new_it, hv);
        -:  600:}
        -:  601:
        -:  602:/*
        -:  603: * Unlinks an item from the LRU and hashtable.
        -:  604: */
     2670:  605:void item_unlink(item *item) {
     2670:  606:    uint32_t hv;
     2670:  607:    hv = hash(ITEM_key(item), item->nkey);
     2670:  608:    item_lock(hv);
     2670:  609:    do_item_unlink(item, hv);
     2670:  610:    item_unlock(hv);
     2670:  611:}
        -:  612:
        -:  613:/*
        -:  614: * Moves an item to the back of the LRU queue.
        -:  615: */
    32239:  616:void item_update(item *item) {
    32239:  617:    uint32_t hv;
    32239:  618:    hv = hash(ITEM_key(item), item->nkey);
        -:  619:
    32239:  620:    item_lock(hv);
    32239:  621:    do_item_update(item);
    32239:  622:    item_unlock(hv);
    32239:  623:}
        -:  624:
        -:  625:/*
        -:  626: * Does arithmetic on a numeric item value.
        -:  627: */
      398:  628:enum delta_result_type add_delta(conn *c, const char *key,
        -:  629:                                 const size_t nkey, int incr,
        -:  630:                                 const int64_t delta, char *buf,
        -:  631:                                 uint64_t *cas) {
      398:  632:    enum delta_result_type ret;
      398:  633:    uint32_t hv;
        -:  634:
      398:  635:    hv = hash(key, nkey);
      398:  636:    item_lock(hv);
      398:  637:    ret = do_add_delta(c, key, nkey, incr, delta, buf, cas, hv);
      398:  638:    item_unlock(hv);
      398:  639:    return ret;
        -:  640:}
        -:  641:
        -:  642:/*
        -:  643: * Stores an item in the cache (high level, obeys set/add/replace semantics)
        -:  644: */
   102442:  645:enum store_item_type store_item(item *item, int comm, conn* c) {
   102442:  646:    enum store_item_type ret;
   102442:  647:    uint32_t hv;
        -:  648:
   102442:  649:    hv = hash(ITEM_key(item), item->nkey);
   102442:  650:    item_lock(hv);
   102442:  651:    ret = do_store_item(item, comm, c, hv);
   102442:  652:    item_unlock(hv);
   102442:  653:    return ret;
        -:  654:}
        -:  655:
        -:  656:/******************************* GLOBAL STATS ******************************/
        -:  657:
  260728*:  658:void STATS_LOCK() {
  260728*:  659:    pthread_mutex_lock(&stats_lock);
   260725:  660:}
        -:  661:
  260728*:  662:void STATS_UNLOCK() {
  260728*:  663:    pthread_mutex_unlock(&stats_lock);
   260725:  664:}
        -:  665:
        3:  666:void threadlocal_stats_reset(void) {
        3:  667:    int ii;
       15:  668:    for (ii = 0; ii < settings.num_threads; ++ii) {
       12:  669:        pthread_mutex_lock(&threads[ii].stats.mutex);
        -:  670:#define X(name) threads[ii].stats.name = 0;
       12:  671:        THREAD_STATS_FIELDS
        -:  672:#undef X
        -:  673:
       12:  674:        memset(&threads[ii].stats.slab_stats, 0,
        -:  675:                sizeof(threads[ii].stats.slab_stats));
        -:  676:
       12:  677:        pthread_mutex_unlock(&threads[ii].stats.mutex);
        -:  678:    }
        3:  679:}
        -:  680:
     2793:  681:void threadlocal_stats_aggregate(struct thread_stats *stats) {
     2793:  682:    int ii, sid;
        -:  683:
        -:  684:    /* The struct has a mutex, but we can safely set the whole thing
        -:  685:     * to zero since it is unused when aggregating. */
     2793:  686:    memset(stats, 0, sizeof(*stats));
        -:  687:
    13965:  688:    for (ii = 0; ii < settings.num_threads; ++ii) {
    11172:  689:        pthread_mutex_lock(&threads[ii].stats.mutex);
        -:  690:#define X(name) stats->name += threads[ii].stats.name;
    11172:  691:        THREAD_STATS_FIELDS
        -:  692:#undef X
        -:  693:
   726180:  694:        for (sid = 0; sid < MAX_NUMBER_OF_SLAB_CLASSES; sid++) {
        -:  695:#define X(name) stats->slab_stats[sid].name += \
        -:  696:            threads[ii].stats.slab_stats[sid].name;
   715008:  697:            SLAB_STATS_FIELDS
        -:  698:#undef X
        -:  699:        }
        -:  700:
    11172:  701:        pthread_mutex_unlock(&threads[ii].stats.mutex);
        -:  702:    }
     2793:  703:}
        -:  704:
     2770:  705:void slab_stats_aggregate(struct thread_stats *stats, struct slab_stats *out) {
     2770:  706:    int sid;
        -:  707:
     2770:  708:    memset(out, 0, sizeof(*out));
        -:  709:
   180050:  710:    for (sid = 0; sid < MAX_NUMBER_OF_SLAB_CLASSES; sid++) {
        -:  711:#define X(name) out->name += stats->slab_stats[sid].name;
   177280:  712:        SLAB_STATS_FIELDS
        -:  713:#undef X
        -:  714:    }
     2770:  715:}
        -:  716:
        -:  717:/*
        -:  718: * Initializes the thread subsystem, creating various worker threads.
        -:  719: *
        -:  720: * nthreads  Number of worker event handler threads to spawn
        -:  721: */
       89:  722:void memcached_thread_init(int nthreads) {
       89:  723:    int         i;
       89:  724:    int         power;
        -:  725:
    22873:  726:    for (i = 0; i < POWER_LARGEST; i++) {
    22784:  727:        pthread_mutex_init(&lru_locks[i], NULL);
        -:  728:    }
       89:  729:    pthread_mutex_init(&worker_hang_lock, NULL);
        -:  730:
       89:  731:    pthread_mutex_init(&init_lock, NULL);
       89:  732:    pthread_cond_init(&init_cond, NULL);
        -:  733:
       89:  734:    pthread_mutex_init(&cqi_freelist_lock, NULL);
       89:  735:    cqi_freelist = NULL;
        -:  736:
        -:  737:    /* Want a wide lock table, but don't waste memory */
       89:  738:    if (nthreads < 3) {
        -:  739:        power = 10;
       89:  740:    } else if (nthreads < 4) {
        -:  741:        power = 11;
       89:  742:    } else if (nthreads < 5) {
        -:  743:        power = 12;
    #####:  744:    } else if (nthreads <= 10) {
        -:  745:        power = 13;
    #####:  746:    } else if (nthreads <= 20) {
        -:  747:        power = 14;
        -:  748:    } else {
        -:  749:        /* 32k buckets. just under the hashpower default. */
    #####:  750:        power = 15;
        -:  751:    }
        -:  752:
       89:  753:    if (power >= hashpower) {
    #####:  754:        fprintf(stderr, "Hash table power size (%d) cannot be equal to or less than item lock table (%d)\n", hashpower, power);
    #####:  755:        fprintf(stderr, "Item lock table grows with `-t N` (worker threadcount)\n");
    #####:  756:        fprintf(stderr, "Hash table grows with `-o hashpower=N` \n");
    #####:  757:        exit(1);
        -:  758:    }
        -:  759:
       89:  760:    item_lock_count = hashsize(power);
       89:  761:    item_lock_hashpower = power;
        -:  762:
       89:  763:    item_locks = calloc(item_lock_count, sizeof(pthread_mutex_t));
       89:  764:    if (! item_locks) {
    #####:  765:        perror("Can't allocate item locks");
    #####:  766:        exit(1);
        -:  767:    }
   364633:  768:    for (i = 0; i < item_lock_count; i++) {
   364544:  769:        pthread_mutex_init(&item_locks[i], NULL);
        -:  770:    }
        -:  771:
       89:  772:    threads = calloc(nthreads, sizeof(LIBEVENT_THREAD));
       89:  773:    if (! threads) {
    #####:  774:        perror("Can't allocate thread descriptors");
    #####:  775:        exit(1);
        -:  776:    }
        -:  777:
      445:  778:    for (i = 0; i < nthreads; i++) {
      356:  779:        int fds[2];
      356:  780:        if (pipe(fds)) {
    #####:  781:            perror("Can't create notify pipe");
    #####:  782:            exit(1);
        -:  783:        }
        -:  784:
      356:  785:        threads[i].notify_receive_fd = fds[0];
      356:  786:        threads[i].notify_send_fd = fds[1];
        -:  787:
      356:  788:        setup_thread(&threads[i]);
        -:  789:        /* Reserve three fds for the libevent base, and two for the pipe */
      356:  790:        stats_state.reserved_fds += 5;
        -:  791:    }
        -:  792:
        -:  793:    /* Create threads after we've done all the libevent setup. */
      445:  794:    for (i = 0; i < nthreads; i++) {
      356:  795:        create_worker(worker_libevent, &threads[i]);
        -:  796:    }
        -:  797:
        -:  798:    /* Wait for all the threads to set themselves up before returning. */
       89:  799:    pthread_mutex_lock(&init_lock);
       89:  800:    wait_for_thread_registration(nthreads);
       89:  801:    pthread_mutex_unlock(&init_lock);
       89:  802:}
        -:  803:
